{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?', '!','.']\n",
    "data_file = open('intents.json').read()\n",
    "intents = json.loads(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        words.extend(w)\n",
    "        documents.append((w, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 documents\n"
     ]
    }
   ],
   "source": [
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "print (len(documents), \"documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 classes ['goodbye', 'greeting', 'noanswer', 'question1', 'question10', 'question11', 'question12', 'question13', 'question14', 'question15', 'question16', 'question17', 'question18', 'question19', 'question2', 'question20', 'question21', 'question22', 'question23', 'question24', 'question25', 'question26', 'question27', 'question28', 'question29', 'question3', 'question30', 'question31', 'question32', 'question33', 'question34', 'question35', 'question36', 'question37', 'question38', 'question39', 'question4', 'question40', 'question41', 'question42', 'question43', 'question44', 'question45', 'question46', 'question47', 'question48', 'question49', 'question5', 'question50', 'question51', 'question52', 'question53', 'question54', 'question55', 'question56', 'question57', 'question58', 'question59', 'question6', 'question60', 'question61', 'question62', 'question63', 'question64', 'question65', 'question66', 'question67', 'question68', 'question7', 'question8', 'question9', 'thanks']\n",
      "366 unique lemmatized words ['%', \"'m\", \"'s\", ',', '0', '1', '14', '2', '2nd', '3', '6', '7', ':', '[', ']', 'a', 'able', 'about', 'accepted', 'access', 'accessing', 'account', 'added', 'affect', 'after', 'again', 'ai', 'all', 'already', 'also', 'am', 'an', 'and', 'another', 'any', 'anyone', 'anything', 'applying', 'appointment', 'are', 'ask', 'assignment', 'attend', 'awesome', 'basic', 'be', 'becomes', 'before', 'bitrix24', 'blockchain', 'both', 'browser', 'but', 'button', 'by', 'bye', 'ca', 'can', 'case', 'certificate', 'certification', 'change', 'chatting', 'check', 'choose', 'choosen', 'chosen', 'clear', 'clearing', 'clicked', 'clock', 'clock-in', 'clock-out', 'cloud', 'code', 'college', 'company', 'complete', 'completed', 'completing', 'completion', 'compulsorily', 'compulsory', 'computing', 'consist', 'content', 'continue', 'continuing', 'could', 'counsealge', 'counselage', 'day', 'development', 'did', 'different', 'do', 'document', 'domain', 'done', 'doubt', 'download', 'efficiency', 'else', 'enough', 'entire', 'error', 'etc', 'even', 'every', 'exam', 'exception', 'expect', 'extend', 'few', 'find', 'finish', 'finished', 'first', 'follow', 'for', 'forgot', 'found', 'from', 'further', 'future', 'general', 'get', 'getting', 'give', 'given', 'going', 'good', 'goodbye', 'group', 'ha', 'had', 'happens', 'have', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'hired', 'hola', 'home', 'hour', 'how', 'hy000', 'i', 'if', 'in', 'increase', 'individual', 'individually', 'induction', 'instruction', 'intern', 'internship', 'intership', 'introduction', 'invalid', 'ip', 'is', 'issue', 'it', 'job', 'joined', 'just', 'kind', 'know', 'last', 'later', 'layout', 'le', 'learn', 'learned', 'learning', 'leave', 'letter', 'link', 'live', 'load', 'log', 'login', 'lp', 'lp1', 'lp1/', 'lp2', 'lp2/', 'lp3', 'm', 'mandatory', 'many', 'me', 'medium', 'mention', 'mentioned', 'mentorship', 'menu', 'mix', 'mixture', 'ml', 'mobile', 'module', 'more', 'much', 'my', \"n't\", 'necessary', 'need', 'next', 'nice', 'no', 'not', 'now', 'of', 'offer', 'ok', 'okay', 'on', 'one', 'ongoing', 'online', 'only', 'opted', 'option', 'or', 'other', 'our', 'own', 'page', 'page-', 'part', 'pas', 'path', 'phone', 'point', 'police', 'policy', 'press', 'pressing', 'problem', 'profile', 'program', 'progress', 'project', 'proper', 'properly', 'provide', 'provided', 'push', 'put', 'query', 'quiz', 'reason', 'recommended', 'record', 'redirection', 'redirects', 'register', 'relate', 'report', 'resource', 'respect', 'result', 'resume', 'said', 'same', 'score', 'see', 'selected', 'session', 'share', 'shared', 'should', 'show', 'showing', 'six', 'skip', 'so', 'social', 'some', 'someone', 'somwhere', 'sqlstate', 'start', 'statement', 'step', 'still', 'stipend', 'study', 'submission', 'submit', 'submitted', 'such', 'switch', 'table', 'take', 'taken', 'taking', 'task', 'team', 'tech', 'technology', 'tell', 'telling', 'tenhnology', 'than', 'thank', 'thanks', 'that', 'the', 'them', 'then', 'there', 'these', 'this', 'those', 'till', 'time', 'to', 'token', 'too', 'topic', 'track', 'trainig', 'training', 'traning', 'trying', 'u', 'unable', 'understanding', 'university', 'use', 'user', 'video', 'view', 'wa', 'want', 'way', 'we', 'web', 'website', 'week', 'weekly', 'well', 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'within', 'work', 'workgroup', 'working', 'write', 'yet', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "classes = sorted(list(set(classes)))\n",
    "print (len(classes), \"classes\", classes)\n",
    "print (len(words), \"unique lemmatized words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(words,open('words.pkl','wb'))\n",
    "pickle.dump(classes,open('classes.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "for doc in documents:\n",
    "    bag = []\n",
    "    pattern_words = doc[0]\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    training.append([bag, output_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data created\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])\n",
    "print(\"Training data created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.90 and logs.get('loss')<0.40):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "model = Sequential()\n",
    "model.add(Dense(132, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(38, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 132)               48444     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 132)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 38)                5054      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 38)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 72)                2808      \n",
      "=================================================================\n",
      "Total params: 56,306\n",
      "Trainable params: 56,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/1500\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 4.3107 - accuracy: 0.0053\n",
      "Epoch 2/1500\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 4.2588 - accuracy: 0.0316\n",
      "Epoch 3/1500\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 4.2441 - accuracy: 0.0474\n",
      "Epoch 4/1500\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 4.2109 - accuracy: 0.0421\n",
      "Epoch 5/1500\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 4.1734 - accuracy: 0.0789\n",
      "Epoch 6/1500\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 4.1636 - accuracy: 0.0684\n",
      "Epoch 7/1500\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 4.1187 - accuracy: 0.0579\n",
      "Epoch 8/1500\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 4.0270 - accuracy: 0.1000\n",
      "Epoch 9/1500\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 4.0337 - accuracy: 0.0947\n",
      "Epoch 10/1500\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 3.9622 - accuracy: 0.1053\n",
      "Epoch 11/1500\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 3.8872 - accuracy: 0.0842\n",
      "Epoch 12/1500\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 3.8325 - accuracy: 0.1474\n",
      "Epoch 13/1500\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 3.7386 - accuracy: 0.1684\n",
      "Epoch 14/1500\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 3.7563 - accuracy: 0.1526\n",
      "Epoch 15/1500\n",
      "190/190 [==============================] - 0s 959us/step - loss: 3.6178 - accuracy: 0.1789\n",
      "Epoch 16/1500\n",
      "190/190 [==============================] - 0s 932us/step - loss: 3.5694 - accuracy: 0.1526\n",
      "Epoch 17/1500\n",
      "190/190 [==============================] - 0s 927us/step - loss: 3.4600 - accuracy: 0.2053\n",
      "Epoch 18/1500\n",
      "190/190 [==============================] - 0s 990us/step - loss: 3.3695 - accuracy: 0.21580s - loss: 3.3563 - accuracy: 0.21\n",
      "Epoch 19/1500\n",
      "190/190 [==============================] - 0s 927us/step - loss: 3.1859 - accuracy: 0.2211\n",
      "Epoch 20/1500\n",
      "190/190 [==============================] - 0s 980us/step - loss: 3.1443 - accuracy: 0.2105\n",
      "Epoch 21/1500\n",
      "190/190 [==============================] - 0s 801us/step - loss: 3.0957 - accuracy: 0.2579\n",
      "Epoch 22/1500\n",
      "190/190 [==============================] - 0s 769us/step - loss: 3.0872 - accuracy: 0.2737\n",
      "Epoch 23/1500\n",
      "190/190 [==============================] - 0s 743us/step - loss: 2.8041 - accuracy: 0.2842\n",
      "Epoch 24/1500\n",
      "190/190 [==============================] - 0s 806us/step - loss: 2.8647 - accuracy: 0.2316\n",
      "Epoch 25/1500\n",
      "190/190 [==============================] - 0s 769us/step - loss: 2.7433 - accuracy: 0.2842\n",
      "Epoch 26/1500\n",
      "190/190 [==============================] - 0s 885us/step - loss: 2.6930 - accuracy: 0.3789\n",
      "Epoch 27/1500\n",
      "190/190 [==============================] - 0s 769us/step - loss: 2.5209 - accuracy: 0.3947\n",
      "Epoch 28/1500\n",
      "190/190 [==============================] - 0s 801us/step - loss: 2.5365 - accuracy: 0.3526\n",
      "Epoch 29/1500\n",
      "190/190 [==============================] - 0s 669us/step - loss: 2.4438 - accuracy: 0.3579\n",
      "Epoch 30/1500\n",
      "190/190 [==============================] - 0s 779us/step - loss: 2.5229 - accuracy: 0.3474\n",
      "Epoch 31/1500\n",
      "190/190 [==============================] - 0s 716us/step - loss: 2.2669 - accuracy: 0.3947\n",
      "Epoch 32/1500\n",
      "190/190 [==============================] - 0s 848us/step - loss: 2.2467 - accuracy: 0.4000\n",
      "Epoch 33/1500\n",
      "190/190 [==============================] - 0s 769us/step - loss: 2.1764 - accuracy: 0.4368\n",
      "Epoch 34/1500\n",
      "190/190 [==============================] - 0s 764us/step - loss: 1.9747 - accuracy: 0.4789\n",
      "Epoch 35/1500\n",
      "190/190 [==============================] - 0s 727us/step - loss: 2.0444 - accuracy: 0.4474\n",
      "Epoch 36/1500\n",
      "190/190 [==============================] - 0s 743us/step - loss: 2.0940 - accuracy: 0.4211\n",
      "Epoch 37/1500\n",
      "190/190 [==============================] - 0s 774us/step - loss: 1.9177 - accuracy: 0.4947\n",
      "Epoch 38/1500\n",
      "190/190 [==============================] - 0s 895us/step - loss: 1.9523 - accuracy: 0.4474\n",
      "Epoch 39/1500\n",
      "190/190 [==============================] - 0s 806us/step - loss: 2.0730 - accuracy: 0.4263\n",
      "Epoch 40/1500\n",
      "190/190 [==============================] - 0s 695us/step - loss: 1.8468 - accuracy: 0.4947\n",
      "Epoch 41/1500\n",
      "190/190 [==============================] - 0s 753us/step - loss: 1.8432 - accuracy: 0.4895\n",
      "Epoch 42/1500\n",
      "190/190 [==============================] - 0s 748us/step - loss: 1.6427 - accuracy: 0.5526\n",
      "Epoch 43/1500\n",
      "190/190 [==============================] - 0s 780us/step - loss: 1.5928 - accuracy: 0.5632\n",
      "Epoch 44/1500\n",
      "190/190 [==============================] - 0s 732us/step - loss: 1.6199 - accuracy: 0.5158\n",
      "Epoch 45/1500\n",
      "190/190 [==============================] - 0s 806us/step - loss: 1.6905 - accuracy: 0.5368\n",
      "Epoch 46/1500\n",
      "190/190 [==============================] - 0s 732us/step - loss: 1.6346 - accuracy: 0.5158\n",
      "Epoch 47/1500\n",
      "190/190 [==============================] - 0s 695us/step - loss: 1.5416 - accuracy: 0.5842\n",
      "Epoch 48/1500\n",
      "190/190 [==============================] - 0s 774us/step - loss: 1.5713 - accuracy: 0.5316\n",
      "Epoch 49/1500\n",
      "190/190 [==============================] - 0s 769us/step - loss: 1.4295 - accuracy: 0.5474\n",
      "Epoch 50/1500\n",
      "190/190 [==============================] - 0s 695us/step - loss: 1.3978 - accuracy: 0.6263\n",
      "Epoch 51/1500\n",
      "190/190 [==============================] - 0s 766us/step - loss: 1.4687 - accuracy: 0.6368\n",
      "Epoch 52/1500\n",
      "190/190 [==============================] - 0s 632us/step - loss: 1.5220 - accuracy: 0.5895\n",
      "Epoch 53/1500\n",
      "190/190 [==============================] - 0s 590us/step - loss: 1.4222 - accuracy: 0.5895\n",
      "Epoch 54/1500\n",
      "190/190 [==============================] - 0s 627us/step - loss: 1.2834 - accuracy: 0.6632\n",
      "Epoch 55/1500\n",
      "190/190 [==============================] - 0s 574us/step - loss: 1.4216 - accuracy: 0.5526\n",
      "Epoch 56/1500\n",
      "190/190 [==============================] - 0s 616us/step - loss: 1.2883 - accuracy: 0.6263\n",
      "Epoch 57/1500\n",
      "190/190 [==============================] - 0s 579us/step - loss: 1.2446 - accuracy: 0.5947\n",
      "Epoch 58/1500\n",
      "190/190 [==============================] - 0s 527us/step - loss: 1.3384 - accuracy: 0.6105\n",
      "Epoch 59/1500\n",
      "190/190 [==============================] - 0s 490us/step - loss: 1.1198 - accuracy: 0.6842\n",
      "Epoch 60/1500\n",
      "190/190 [==============================] - 0s 479us/step - loss: 1.2147 - accuracy: 0.6474\n",
      "Epoch 61/1500\n",
      "190/190 [==============================] - 0s 637us/step - loss: 1.2785 - accuracy: 0.5842\n",
      "Epoch 62/1500\n",
      "190/190 [==============================] - 0s 564us/step - loss: 1.0612 - accuracy: 0.6842\n",
      "Epoch 63/1500\n",
      "190/190 [==============================] - 0s 548us/step - loss: 1.2143 - accuracy: 0.6105\n",
      "Epoch 64/1500\n",
      "190/190 [==============================] - 0s 485us/step - loss: 1.2719 - accuracy: 0.6526\n",
      "Epoch 65/1500\n",
      "190/190 [==============================] - 0s 485us/step - loss: 1.2384 - accuracy: 0.6632\n",
      "Epoch 66/1500\n",
      "190/190 [==============================] - 0s 495us/step - loss: 1.0786 - accuracy: 0.6737\n",
      "Epoch 67/1500\n",
      "190/190 [==============================] - 0s 495us/step - loss: 1.1883 - accuracy: 0.6211\n",
      "Epoch 68/1500\n",
      "190/190 [==============================] - 0s 553us/step - loss: 1.2690 - accuracy: 0.6316\n",
      "Epoch 69/1500\n",
      "190/190 [==============================] - 0s 558us/step - loss: 1.1232 - accuracy: 0.6053\n",
      "Epoch 70/1500\n",
      "190/190 [==============================] - 0s 606us/step - loss: 1.1158 - accuracy: 0.6474\n",
      "Epoch 71/1500\n",
      "190/190 [==============================] - 0s 537us/step - loss: 1.0948 - accuracy: 0.6789\n",
      "Epoch 72/1500\n",
      "190/190 [==============================] - 0s 542us/step - loss: 1.2194 - accuracy: 0.6421\n",
      "Epoch 73/1500\n",
      "190/190 [==============================] - 0s 495us/step - loss: 1.0714 - accuracy: 0.6737\n",
      "Epoch 74/1500\n",
      "190/190 [==============================] - 0s 485us/step - loss: 1.0828 - accuracy: 0.6684\n",
      "Epoch 75/1500\n",
      "190/190 [==============================] - 0s 490us/step - loss: 1.0579 - accuracy: 0.6842\n",
      "Epoch 76/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 0s 511us/step - loss: 1.0652 - accuracy: 0.6368\n",
      "Epoch 77/1500\n",
      "190/190 [==============================] - ETA: 0s - loss: 0.9920 - accuracy: 0.73 - 0s 363us/step - loss: 1.0076 - accuracy: 0.7053\n",
      "Epoch 78/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 1.0624 - accuracy: 0.6737\n",
      "Epoch 79/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.9650 - accuracy: 0.7053\n",
      "Epoch 80/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 1.1005 - accuracy: 0.6632\n",
      "Epoch 81/1500\n",
      "190/190 [==============================] - 0s 411us/step - loss: 1.1255 - accuracy: 0.6789\n",
      "Epoch 82/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 1.0108 - accuracy: 0.6632\n",
      "Epoch 83/1500\n",
      "190/190 [==============================] - 0s 395us/step - loss: 1.0199 - accuracy: 0.7105\n",
      "Epoch 84/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.9796 - accuracy: 0.6895\n",
      "Epoch 85/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.8357 - accuracy: 0.7579\n",
      "Epoch 86/1500\n",
      "190/190 [==============================] - 0s 348us/step - loss: 1.0664 - accuracy: 0.6789\n",
      "Epoch 87/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.8744 - accuracy: 0.7263\n",
      "Epoch 88/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.8533 - accuracy: 0.7579\n",
      "Epoch 89/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.9996 - accuracy: 0.6842\n",
      "Epoch 90/1500\n",
      "190/190 [==============================] - 0s 395us/step - loss: 0.8979 - accuracy: 0.7000\n",
      "Epoch 91/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.9556 - accuracy: 0.7316\n",
      "Epoch 92/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.9067 - accuracy: 0.7368\n",
      "Epoch 93/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.7700 - accuracy: 0.7737\n",
      "Epoch 94/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.9595 - accuracy: 0.6684\n",
      "Epoch 95/1500\n",
      "190/190 [==============================] - 0s 432us/step - loss: 0.9402 - accuracy: 0.6947\n",
      "Epoch 96/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.7883 - accuracy: 0.7526\n",
      "Epoch 97/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.8615 - accuracy: 0.7632\n",
      "Epoch 98/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.8602 - accuracy: 0.7263\n",
      "Epoch 99/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 1.0076 - accuracy: 0.7000\n",
      "Epoch 100/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.7299 - accuracy: 0.7421\n",
      "Epoch 101/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.9159 - accuracy: 0.6842\n",
      "Epoch 102/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.8661 - accuracy: 0.6895\n",
      "Epoch 103/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.8551 - accuracy: 0.7368\n",
      "Epoch 104/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.7859 - accuracy: 0.7684\n",
      "Epoch 105/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.9058 - accuracy: 0.7105\n",
      "Epoch 106/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.6665 - accuracy: 0.8158\n",
      "Epoch 107/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.7684 - accuracy: 0.7526\n",
      "Epoch 108/1500\n",
      "190/190 [==============================] - 0s 400us/step - loss: 0.8694 - accuracy: 0.7421\n",
      "Epoch 109/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.9247 - accuracy: 0.7158\n",
      "Epoch 110/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.9799 - accuracy: 0.7053\n",
      "Epoch 111/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.6700 - accuracy: 0.8105\n",
      "Epoch 112/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.6874 - accuracy: 0.8000\n",
      "Epoch 113/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.9001 - accuracy: 0.7316\n",
      "Epoch 114/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.7538 - accuracy: 0.7789\n",
      "Epoch 115/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.6831 - accuracy: 0.7947\n",
      "Epoch 116/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.7543 - accuracy: 0.7684\n",
      "Epoch 117/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.6913 - accuracy: 0.7947\n",
      "Epoch 118/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.6748 - accuracy: 0.7947\n",
      "Epoch 119/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.6002 - accuracy: 0.8368\n",
      "Epoch 120/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.8212 - accuracy: 0.7684\n",
      "Epoch 121/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.7833 - accuracy: 0.7842\n",
      "Epoch 122/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.8309 - accuracy: 0.7368\n",
      "Epoch 123/1500\n",
      "190/190 [==============================] - 0s 411us/step - loss: 0.6765 - accuracy: 0.7895\n",
      "Epoch 124/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.6155 - accuracy: 0.8211\n",
      "Epoch 125/1500\n",
      "190/190 [==============================] - 0s 421us/step - loss: 0.7338 - accuracy: 0.7632\n",
      "Epoch 126/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.7232 - accuracy: 0.7474\n",
      "Epoch 127/1500\n",
      "190/190 [==============================] - 0s 384us/step - loss: 0.7331 - accuracy: 0.8000\n",
      "Epoch 128/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.6121 - accuracy: 0.8316\n",
      "Epoch 129/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.6414 - accuracy: 0.8263\n",
      "Epoch 130/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.6381 - accuracy: 0.8105\n",
      "Epoch 131/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.7127 - accuracy: 0.7579\n",
      "Epoch 132/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.6983 - accuracy: 0.7842\n",
      "Epoch 133/1500\n",
      "190/190 [==============================] - 0s 400us/step - loss: 0.7171 - accuracy: 0.7579\n",
      "Epoch 134/1500\n",
      "190/190 [==============================] - 0s 406us/step - loss: 0.6868 - accuracy: 0.7737\n",
      "Epoch 135/1500\n",
      "190/190 [==============================] - 0s 448us/step - loss: 0.6718 - accuracy: 0.7947\n",
      "Epoch 136/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.7488 - accuracy: 0.7316\n",
      "Epoch 137/1500\n",
      "190/190 [==============================] - 0s 395us/step - loss: 0.7680 - accuracy: 0.7632\n",
      "Epoch 138/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.6484 - accuracy: 0.8053\n",
      "Epoch 139/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.6408 - accuracy: 0.7895\n",
      "Epoch 140/1500\n",
      "190/190 [==============================] - 0s 395us/step - loss: 0.7152 - accuracy: 0.7474\n",
      "Epoch 141/1500\n",
      "190/190 [==============================] - 0s 385us/step - loss: 0.6488 - accuracy: 0.7895\n",
      "Epoch 142/1500\n",
      "190/190 [==============================] - 0s 384us/step - loss: 0.7039 - accuracy: 0.7579\n",
      "Epoch 143/1500\n",
      "190/190 [==============================] - 0s 395us/step - loss: 0.6752 - accuracy: 0.7895\n",
      "Epoch 144/1500\n",
      "190/190 [==============================] - 0s 400us/step - loss: 0.5971 - accuracy: 0.7842\n",
      "Epoch 145/1500\n",
      "190/190 [==============================] - 0s 384us/step - loss: 0.7770 - accuracy: 0.7316\n",
      "Epoch 146/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.6375 - accuracy: 0.7842\n",
      "Epoch 147/1500\n",
      "190/190 [==============================] - 0s 384us/step - loss: 0.6588 - accuracy: 0.7737\n",
      "Epoch 148/1500\n",
      "190/190 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.76 - 0s 437us/step - loss: 0.5956 - accuracy: 0.7737\n",
      "Epoch 149/1500\n",
      "190/190 [==============================] - 0s 416us/step - loss: 0.6286 - accuracy: 0.7632\n",
      "Epoch 150/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.6103 - accuracy: 0.8000\n",
      "Epoch 151/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.6143 - accuracy: 0.7947\n",
      "Epoch 152/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 0s 395us/step - loss: 0.6344 - accuracy: 0.8000\n",
      "Epoch 153/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.5843 - accuracy: 0.8526\n",
      "Epoch 154/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.6506 - accuracy: 0.8105\n",
      "Epoch 155/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.6075 - accuracy: 0.8000\n",
      "Epoch 156/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.7838 - accuracy: 0.7526\n",
      "Epoch 157/1500\n",
      "190/190 [==============================] - 0s 364us/step - loss: 0.5700 - accuracy: 0.8000\n",
      "Epoch 158/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.5666 - accuracy: 0.8474\n",
      "Epoch 159/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.6676 - accuracy: 0.7684\n",
      "Epoch 160/1500\n",
      "190/190 [==============================] - 0s 400us/step - loss: 0.7618 - accuracy: 0.7421\n",
      "Epoch 161/1500\n",
      "190/190 [==============================] - 0s 448us/step - loss: 0.6579 - accuracy: 0.7789\n",
      "Epoch 162/1500\n",
      "190/190 [==============================] - 0s 384us/step - loss: 0.6592 - accuracy: 0.8000\n",
      "Epoch 163/1500\n",
      "190/190 [==============================] - 0s 432us/step - loss: 0.7171 - accuracy: 0.7474\n",
      "Epoch 164/1500\n",
      "190/190 [==============================] - 0s 690us/step - loss: 0.6624 - accuracy: 0.7737\n",
      "Epoch 165/1500\n",
      "190/190 [==============================] - 0s 585us/step - loss: 0.5957 - accuracy: 0.8263\n",
      "Epoch 166/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.6718 - accuracy: 0.7947\n",
      "Epoch 167/1500\n",
      "190/190 [==============================] - 0s 606us/step - loss: 0.6181 - accuracy: 0.7842\n",
      "Epoch 168/1500\n",
      "190/190 [==============================] - 0s 732us/step - loss: 0.5798 - accuracy: 0.8000\n",
      "Epoch 169/1500\n",
      "190/190 [==============================] - 0s 432us/step - loss: 0.5764 - accuracy: 0.7842\n",
      "Epoch 170/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.7858 - accuracy: 0.7684\n",
      "Epoch 171/1500\n",
      "190/190 [==============================] - 0s 432us/step - loss: 0.6060 - accuracy: 0.8053\n",
      "Epoch 172/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.7064 - accuracy: 0.7895\n",
      "Epoch 173/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.6659 - accuracy: 0.7947\n",
      "Epoch 174/1500\n",
      "190/190 [==============================] - 0s 485us/step - loss: 0.5655 - accuracy: 0.8158\n",
      "Epoch 175/1500\n",
      "190/190 [==============================] - 0s 479us/step - loss: 0.6985 - accuracy: 0.7632\n",
      "Epoch 176/1500\n",
      "190/190 [==============================] - 0s 463us/step - loss: 0.6942 - accuracy: 0.7579\n",
      "Epoch 177/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5793 - accuracy: 0.8053\n",
      "Epoch 178/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.5697 - accuracy: 0.8211\n",
      "Epoch 179/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.6832 - accuracy: 0.8211\n",
      "Epoch 180/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.6208 - accuracy: 0.7895\n",
      "Epoch 181/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.6467 - accuracy: 0.7789\n",
      "Epoch 182/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.7874 - accuracy: 0.7474\n",
      "Epoch 183/1500\n",
      "190/190 [==============================] - 0s 400us/step - loss: 0.5443 - accuracy: 0.8316\n",
      "Epoch 184/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.6809 - accuracy: 0.7632\n",
      "Epoch 185/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.7102 - accuracy: 0.7579\n",
      "Epoch 186/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.6182 - accuracy: 0.8000\n",
      "Epoch 187/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.5339 - accuracy: 0.8368\n",
      "Epoch 188/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.6076 - accuracy: 0.8263\n",
      "Epoch 189/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.7061 - accuracy: 0.7684\n",
      "Epoch 190/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.7211 - accuracy: 0.7842\n",
      "Epoch 191/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.5271 - accuracy: 0.8474\n",
      "Epoch 192/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.6857 - accuracy: 0.7842\n",
      "Epoch 193/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.6666 - accuracy: 0.7789\n",
      "Epoch 194/1500\n",
      "190/190 [==============================] - 0s 384us/step - loss: 0.6041 - accuracy: 0.7895\n",
      "Epoch 195/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.7020 - accuracy: 0.7789\n",
      "Epoch 196/1500\n",
      "190/190 [==============================] - 0s 384us/step - loss: 0.5223 - accuracy: 0.8368\n",
      "Epoch 197/1500\n",
      "190/190 [==============================] - 0s 442us/step - loss: 0.6439 - accuracy: 0.7895\n",
      "Epoch 198/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.5274 - accuracy: 0.8368\n",
      "Epoch 199/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.6446 - accuracy: 0.7842\n",
      "Epoch 200/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.5557 - accuracy: 0.8421\n",
      "Epoch 201/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.5457 - accuracy: 0.8000\n",
      "Epoch 202/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.5801 - accuracy: 0.8053\n",
      "Epoch 203/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.5418 - accuracy: 0.8368\n",
      "Epoch 204/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5602 - accuracy: 0.8211\n",
      "Epoch 205/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.6316 - accuracy: 0.7947\n",
      "Epoch 206/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.6770 - accuracy: 0.7895\n",
      "Epoch 207/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.5639 - accuracy: 0.8263\n",
      "Epoch 208/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.6767 - accuracy: 0.7789\n",
      "Epoch 209/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.5557 - accuracy: 0.8158\n",
      "Epoch 210/1500\n",
      "190/190 [==============================] - 0s 432us/step - loss: 0.7123 - accuracy: 0.7579\n",
      "Epoch 211/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.6217 - accuracy: 0.8000\n",
      "Epoch 212/1500\n",
      "190/190 [==============================] - 0s 400us/step - loss: 0.6803 - accuracy: 0.7947\n",
      "Epoch 213/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.5811 - accuracy: 0.8316\n",
      "Epoch 214/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.5595 - accuracy: 0.8316\n",
      "Epoch 215/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.5737 - accuracy: 0.8105\n",
      "Epoch 216/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.5069 - accuracy: 0.8526\n",
      "Epoch 217/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.4992 - accuracy: 0.8526\n",
      "Epoch 218/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.5997 - accuracy: 0.7895\n",
      "Epoch 219/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.5182 - accuracy: 0.8474\n",
      "Epoch 220/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.5307 - accuracy: 0.8053\n",
      "Epoch 221/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.5621 - accuracy: 0.8105\n",
      "Epoch 222/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5182 - accuracy: 0.8105\n",
      "Epoch 223/1500\n",
      "190/190 [==============================] - 0s 400us/step - loss: 0.4288 - accuracy: 0.8579\n",
      "Epoch 224/1500\n",
      "190/190 [==============================] - 0s 406us/step - loss: 0.4713 - accuracy: 0.8316\n",
      "Epoch 225/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.5347 - accuracy: 0.8211\n",
      "Epoch 226/1500\n",
      "190/190 [==============================] - 0s 395us/step - loss: 0.5231 - accuracy: 0.8316\n",
      "Epoch 227/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.5747 - accuracy: 0.8474\n",
      "Epoch 228/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.4861 - accuracy: 0.8368\n",
      "Epoch 229/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 0s 374us/step - loss: 0.4446 - accuracy: 0.8579\n",
      "Epoch 230/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.5586 - accuracy: 0.8053\n",
      "Epoch 231/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.5567 - accuracy: 0.8158\n",
      "Epoch 232/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.7100 - accuracy: 0.8000\n",
      "Epoch 233/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.4388 - accuracy: 0.8684\n",
      "Epoch 234/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.5885 - accuracy: 0.8000\n",
      "Epoch 235/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.4550 - accuracy: 0.8526\n",
      "Epoch 236/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.6724 - accuracy: 0.7895\n",
      "Epoch 237/1500\n",
      "190/190 [==============================] - 0s 421us/step - loss: 0.6643 - accuracy: 0.7789\n",
      "Epoch 238/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.5912 - accuracy: 0.8105\n",
      "Epoch 239/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.4380 - accuracy: 0.8421\n",
      "Epoch 240/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.5004 - accuracy: 0.8474\n",
      "Epoch 241/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5377 - accuracy: 0.8053\n",
      "Epoch 242/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.5894 - accuracy: 0.8000\n",
      "Epoch 243/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5606 - accuracy: 0.8000\n",
      "Epoch 244/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5778 - accuracy: 0.8000\n",
      "Epoch 245/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.6846 - accuracy: 0.7947\n",
      "Epoch 246/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5142 - accuracy: 0.8316\n",
      "Epoch 247/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.6623 - accuracy: 0.7895\n",
      "Epoch 248/1500\n",
      "190/190 [==============================] - 0s 364us/step - loss: 0.6022 - accuracy: 0.8053\n",
      "Epoch 249/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.6344 - accuracy: 0.8211\n",
      "Epoch 250/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.5791 - accuracy: 0.8263\n",
      "Epoch 251/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.6119 - accuracy: 0.7789\n",
      "Epoch 252/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.3932 - accuracy: 0.8789\n",
      "Epoch 253/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.4722 - accuracy: 0.8368\n",
      "Epoch 254/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.5972 - accuracy: 0.7842\n",
      "Epoch 255/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.6073 - accuracy: 0.8105\n",
      "Epoch 256/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5236 - accuracy: 0.8263\n",
      "Epoch 257/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.4542 - accuracy: 0.8526\n",
      "Epoch 258/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.6071 - accuracy: 0.7737\n",
      "Epoch 259/1500\n",
      "190/190 [==============================] - 0s 364us/step - loss: 0.6331 - accuracy: 0.8000\n",
      "Epoch 260/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.4955 - accuracy: 0.8263\n",
      "Epoch 261/1500\n",
      "190/190 [==============================] - 0s 448us/step - loss: 0.4663 - accuracy: 0.8316\n",
      "Epoch 262/1500\n",
      "190/190 [==============================] - 0s 442us/step - loss: 0.5231 - accuracy: 0.8474\n",
      "Epoch 263/1500\n",
      "190/190 [==============================] - 0s 421us/step - loss: 0.5729 - accuracy: 0.8579\n",
      "Epoch 264/1500\n",
      "190/190 [==============================] - 0s 469us/step - loss: 0.6216 - accuracy: 0.8105\n",
      "Epoch 265/1500\n",
      "190/190 [==============================] - 0s 448us/step - loss: 0.5603 - accuracy: 0.7947\n",
      "Epoch 266/1500\n",
      "190/190 [==============================] - 0s 442us/step - loss: 0.5238 - accuracy: 0.8053\n",
      "Epoch 267/1500\n",
      "190/190 [==============================] - 0s 442us/step - loss: 0.5717 - accuracy: 0.8211\n",
      "Epoch 268/1500\n",
      "190/190 [==============================] - 0s 427us/step - loss: 0.4578 - accuracy: 0.8368\n",
      "Epoch 269/1500\n",
      "190/190 [==============================] - 0s 463us/step - loss: 0.5022 - accuracy: 0.8421\n",
      "Epoch 270/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.5029 - accuracy: 0.8000\n",
      "Epoch 271/1500\n",
      "190/190 [==============================] - 0s 416us/step - loss: 0.4271 - accuracy: 0.8579\n",
      "Epoch 272/1500\n",
      "190/190 [==============================] - 0s 432us/step - loss: 0.4979 - accuracy: 0.8526\n",
      "Epoch 273/1500\n",
      "190/190 [==============================] - 0s 432us/step - loss: 0.6210 - accuracy: 0.7947\n",
      "Epoch 274/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.4190 - accuracy: 0.8789\n",
      "Epoch 275/1500\n",
      "190/190 [==============================] - 0s 463us/step - loss: 0.4896 - accuracy: 0.8368\n",
      "Epoch 276/1500\n",
      "190/190 [==============================] - 0s 463us/step - loss: 0.4971 - accuracy: 0.8105\n",
      "Epoch 277/1500\n",
      "190/190 [==============================] - 0s 495us/step - loss: 0.6406 - accuracy: 0.8000\n",
      "Epoch 278/1500\n",
      "190/190 [==============================] - 0s 458us/step - loss: 0.6302 - accuracy: 0.7895\n",
      "Epoch 279/1500\n",
      "190/190 [==============================] - 0s 448us/step - loss: 0.5411 - accuracy: 0.8526\n",
      "Epoch 280/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.5368 - accuracy: 0.8316\n",
      "Epoch 281/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.6509 - accuracy: 0.8211\n",
      "Epoch 282/1500\n",
      "190/190 [==============================] - 0s 448us/step - loss: 0.4028 - accuracy: 0.8632\n",
      "Epoch 283/1500\n",
      "190/190 [==============================] - 0s 427us/step - loss: 0.5357 - accuracy: 0.8105\n",
      "Epoch 284/1500\n",
      "190/190 [==============================] - 0s 442us/step - loss: 0.5238 - accuracy: 0.8316\n",
      "Epoch 285/1500\n",
      "190/190 [==============================] - 0s 448us/step - loss: 0.4191 - accuracy: 0.8737\n",
      "Epoch 286/1500\n",
      "190/190 [==============================] - 0s 432us/step - loss: 0.4783 - accuracy: 0.8263\n",
      "Epoch 287/1500\n",
      "190/190 [==============================] - 0s 485us/step - loss: 0.5253 - accuracy: 0.8105\n",
      "Epoch 288/1500\n",
      "190/190 [==============================] - 0s 453us/step - loss: 0.5090 - accuracy: 0.8368\n",
      "Epoch 289/1500\n",
      "190/190 [==============================] - 0s 453us/step - loss: 0.5103 - accuracy: 0.8263\n",
      "Epoch 290/1500\n",
      "190/190 [==============================] - 0s 442us/step - loss: 0.5415 - accuracy: 0.8421\n",
      "Epoch 291/1500\n",
      "190/190 [==============================] - 0s 458us/step - loss: 0.4959 - accuracy: 0.8316\n",
      "Epoch 292/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.5861 - accuracy: 0.8053\n",
      "Epoch 293/1500\n",
      "190/190 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.79 - 0s 437us/step - loss: 0.4880 - accuracy: 0.8105\n",
      "Epoch 294/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.6036 - accuracy: 0.8316\n",
      "Epoch 295/1500\n",
      "190/190 [==============================] - 0s 427us/step - loss: 0.3977 - accuracy: 0.8737\n",
      "Epoch 296/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.4128 - accuracy: 0.8474\n",
      "Epoch 297/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.4911 - accuracy: 0.8263\n",
      "Epoch 298/1500\n",
      "190/190 [==============================] - 0s 453us/step - loss: 0.4353 - accuracy: 0.8368\n",
      "Epoch 299/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.5054 - accuracy: 0.8105\n",
      "Epoch 300/1500\n",
      "190/190 [==============================] - 0s 432us/step - loss: 0.5793 - accuracy: 0.8316\n",
      "Epoch 301/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.4819 - accuracy: 0.8263\n",
      "Epoch 302/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.6066 - accuracy: 0.7947\n",
      "Epoch 303/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.5033 - accuracy: 0.8368\n",
      "Epoch 304/1500\n",
      "190/190 [==============================] - 0s 406us/step - loss: 0.7641 - accuracy: 0.7684\n",
      "Epoch 305/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.4248 - accuracy: 0.8842\n",
      "Epoch 306/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 0s 448us/step - loss: 0.5077 - accuracy: 0.8158\n",
      "Epoch 307/1500\n",
      "190/190 [==============================] - 0s 427us/step - loss: 0.5695 - accuracy: 0.8263\n",
      "Epoch 308/1500\n",
      "190/190 [==============================] - 0s 421us/step - loss: 0.4605 - accuracy: 0.8526\n",
      "Epoch 309/1500\n",
      "190/190 [==============================] - 0s 432us/step - loss: 0.4897 - accuracy: 0.8526\n",
      "Epoch 310/1500\n",
      "190/190 [==============================] - 0s 427us/step - loss: 0.5587 - accuracy: 0.8158\n",
      "Epoch 311/1500\n",
      "190/190 [==============================] - 0s 485us/step - loss: 0.5045 - accuracy: 0.8368\n",
      "Epoch 312/1500\n",
      "190/190 [==============================] - 0s 427us/step - loss: 0.4836 - accuracy: 0.8632\n",
      "Epoch 313/1500\n",
      "190/190 [==============================] - 0s 427us/step - loss: 0.3919 - accuracy: 0.8895\n",
      "Epoch 314/1500\n",
      "190/190 [==============================] - 0s 421us/step - loss: 0.4501 - accuracy: 0.8579\n",
      "Epoch 315/1500\n",
      "190/190 [==============================] - 0s 427us/step - loss: 0.4548 - accuracy: 0.8579\n",
      "Epoch 316/1500\n",
      "190/190 [==============================] - 0s 437us/step - loss: 0.4842 - accuracy: 0.8316\n",
      "Epoch 317/1500\n",
      "190/190 [==============================] - 0s 427us/step - loss: 0.4114 - accuracy: 0.8579\n",
      "Epoch 318/1500\n",
      "190/190 [==============================] - 0s 442us/step - loss: 0.6598 - accuracy: 0.7737\n",
      "Epoch 319/1500\n",
      "190/190 [==============================] - 0s 421us/step - loss: 0.4549 - accuracy: 0.8316\n",
      "Epoch 320/1500\n",
      "190/190 [==============================] - 0s 463us/step - loss: 0.5575 - accuracy: 0.8316\n",
      "Epoch 321/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.4716 - accuracy: 0.8316\n",
      "Epoch 322/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.4383 - accuracy: 0.8474\n",
      "Epoch 323/1500\n",
      "190/190 [==============================] - 0s 427us/step - loss: 0.4928 - accuracy: 0.8368\n",
      "Epoch 324/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5822 - accuracy: 0.8000\n",
      "Epoch 325/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.5196 - accuracy: 0.8316\n",
      "Epoch 326/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.6026 - accuracy: 0.8000\n",
      "Epoch 327/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5731 - accuracy: 0.7947\n",
      "Epoch 328/1500\n",
      "190/190 [==============================] - 0s 383us/step - loss: 0.5166 - accuracy: 0.8158\n",
      "Epoch 329/1500\n",
      "190/190 [==============================] - 0s 408us/step - loss: 0.5609 - accuracy: 0.8316\n",
      "Epoch 330/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.4430 - accuracy: 0.8368\n",
      "Epoch 331/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.4842 - accuracy: 0.8684\n",
      "Epoch 332/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.4991 - accuracy: 0.8368\n",
      "Epoch 333/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.5944 - accuracy: 0.7895\n",
      "Epoch 334/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.5994 - accuracy: 0.8105\n",
      "Epoch 335/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.4087 - accuracy: 0.8579\n",
      "Epoch 336/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.4575 - accuracy: 0.8526\n",
      "Epoch 337/1500\n",
      "190/190 [==============================] - 0s 411us/step - loss: 0.4889 - accuracy: 0.8421\n",
      "Epoch 338/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.4346 - accuracy: 0.8632\n",
      "Epoch 339/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.4543 - accuracy: 0.8368\n",
      "Epoch 340/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.4697 - accuracy: 0.8053\n",
      "Epoch 341/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.6453 - accuracy: 0.7895\n",
      "Epoch 342/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.4496 - accuracy: 0.8368\n",
      "Epoch 343/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.3898 - accuracy: 0.8789\n",
      "Epoch 344/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.4574 - accuracy: 0.8368\n",
      "Epoch 345/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.4595 - accuracy: 0.8421\n",
      "Epoch 346/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.3992 - accuracy: 0.8632\n",
      "Epoch 347/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.4881 - accuracy: 0.8526\n",
      "Epoch 348/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.4102 - accuracy: 0.8474\n",
      "Epoch 349/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.5632 - accuracy: 0.8158\n",
      "Epoch 350/1500\n",
      "190/190 [==============================] - 0s 416us/step - loss: 0.3403 - accuracy: 0.8737\n",
      "Epoch 351/1500\n",
      "190/190 [==============================] - 0s 390us/step - loss: 0.5589 - accuracy: 0.8053\n",
      "Epoch 352/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.4385 - accuracy: 0.8684\n",
      "Epoch 353/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.5594 - accuracy: 0.8000\n",
      "Epoch 354/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.4708 - accuracy: 0.8421\n",
      "Epoch 355/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.5650 - accuracy: 0.7842\n",
      "Epoch 356/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5055 - accuracy: 0.8263\n",
      "Epoch 357/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.5334 - accuracy: 0.8316\n",
      "Epoch 358/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.4573 - accuracy: 0.8474\n",
      "Epoch 359/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.4031 - accuracy: 0.8737\n",
      "Epoch 360/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.4664 - accuracy: 0.8632\n",
      "Epoch 361/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5084 - accuracy: 0.8368\n",
      "Epoch 362/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.4176 - accuracy: 0.8842\n",
      "Epoch 363/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.3714 - accuracy: 0.8737\n",
      "Epoch 364/1500\n",
      "190/190 [==============================] - 0s 432us/step - loss: 0.5390 - accuracy: 0.8158\n",
      "Epoch 365/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.5092 - accuracy: 0.8474\n",
      "Epoch 366/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5535 - accuracy: 0.8316\n",
      "Epoch 367/1500\n",
      "190/190 [==============================] - 0s 416us/step - loss: 0.4942 - accuracy: 0.8263\n",
      "Epoch 368/1500\n",
      "190/190 [==============================] - 0s 490us/step - loss: 0.3996 - accuracy: 0.8737\n",
      "Epoch 369/1500\n",
      "190/190 [==============================] - 0s 474us/step - loss: 0.5525 - accuracy: 0.8263\n",
      "Epoch 370/1500\n",
      "190/190 [==============================] - 0s 421us/step - loss: 0.4246 - accuracy: 0.8526\n",
      "Epoch 371/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.4583 - accuracy: 0.8211\n",
      "Epoch 372/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.5114 - accuracy: 0.8421\n",
      "Epoch 373/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.5391 - accuracy: 0.7947\n",
      "Epoch 374/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.5718 - accuracy: 0.8105\n",
      "Epoch 375/1500\n",
      "190/190 [==============================] - 0s 384us/step - loss: 0.4319 - accuracy: 0.8421\n",
      "Epoch 376/1500\n",
      "190/190 [==============================] - 0s 395us/step - loss: 0.5900 - accuracy: 0.8316\n",
      "Epoch 377/1500\n",
      "190/190 [==============================] - 0s 379us/step - loss: 0.4223 - accuracy: 0.8316\n",
      "Epoch 378/1500\n",
      "190/190 [==============================] - 0s 374us/step - loss: 0.4863 - accuracy: 0.8263\n",
      "Epoch 379/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5912 - accuracy: 0.7947\n",
      "Epoch 380/1500\n",
      "190/190 [==============================] - 0s 369us/step - loss: 0.4866 - accuracy: 0.8579\n",
      "Epoch 381/1500\n",
      "190/190 [==============================] - 0s 363us/step - loss: 0.5850 - accuracy: 0.8158\n",
      "Epoch 382/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.4303 - accuracy: 0.8579\n",
      "Epoch 383/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 0s 384us/step - loss: 0.5714 - accuracy: 0.8421\n",
      "Epoch 384/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.4167 - accuracy: 0.8316\n",
      "Epoch 385/1500\n",
      "190/190 [==============================] - 0s 358us/step - loss: 0.3031 - accuracy: 0.8947\n",
      "Epoch 386/1500\n",
      "190/190 [==============================] - 0s 353us/step - loss: 0.3028 - accuracy: 0.9211\n",
      "\n",
      "Reached 90% accuracy so cancelling training!\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(np.array(train_x), np.array(train_y), epochs=1500, batch_size=5, verbose=1,callbacks=[callbacks])\n",
    "model.save('chatbot.h5', hist)\n",
    "\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('chatbot.h5')\n",
    "import json\n",
    "import random\n",
    "intents = json.loads(open('intents.json').read())\n",
    "words = pickle.load(open('words.pkl','rb'))\n",
    "classes = pickle.load(open('classes.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    sent_words = nltk.word_tokenize(sentence)\n",
    "    sent_words = [lemmatizer.lemmatize(word.lower()) for word in sent_words]\n",
    "    return sent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(sentence, words, show_details=True):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(sentence, model):\n",
    "    p = bow(sentence, words,show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.30\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if(i['tag']== tag):\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def chatbot_response(msg):\n",
    "    ints = predict_class(msg, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: hello\n",
      "Bot: Hello, thanks for asking\n",
      "You: hey there\n",
      "Bot: Good to see you again\n",
      "You: i can't enter the lp1\n",
      "Bot: Ensure you're using the right token\n",
      "You: tell me about work report\n",
      "Bot: As mentioned in the video, please write what you have done this week and request approval from your supervisor by clicking on send to supervisor.\n",
      "You: can't access the quiz\n",
      "Bot: Please retry after some time in an incognito window\n",
      "You: how to resume task of learning path\n",
      "Bot: You can go back to that task and then click on More and then resume to restart that task\n",
      "You: i want to switch technology\n",
      "Bot: You cannot switch the technology currently. You have to continue with the one you are selected for. In the case of multiple form entries, you just got selected for one of them; the first one that you entered. You cannot make a switch right now\n",
      "You: thanks\n",
      "Bot: Any time!\n",
      "You: quit\n",
      "Bot: Okay\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "resp = []\n",
    "while(flag==True):\n",
    "    try:\n",
    "        res = input('You: ')\n",
    "        if res==\"quit\" or res==\"stop\" or res=='Quit' or res==\"Stop\":\n",
    "            flag=False\n",
    "            print(\"Bot: Okay\")\n",
    "        else:\n",
    "            print('Bot:',chatbot_response(res))\n",
    "    except Exception:\n",
    "        print(\"Bot: Sorry I can't understand\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
